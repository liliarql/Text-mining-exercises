{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liliarql/Text-mining-exercises/blob/main/Ejercicio2_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wG7EP2fFgoTn",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "065c8ad9-38cb-4600-d81a-649180a4e004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting transformers[torch]==4.35.2\n",
            "  Using cached transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (2.31.0)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers[torch]==4.35.2)\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (4.66.4)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.20.3 (from transformers[torch]==4.35.2)\n",
            "  Using cached accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]==4.35.2) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]==4.35.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]==4.35.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]==4.35.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]==4.35.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]==4.35.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]==4.35.2) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, accelerate\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "Successfully installed accelerate-0.32.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 tokenizers-0.15.2 transformers-4.35.2\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.82)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Collecting requests>=2.19.0 (from evaluate)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 evaluate-0.4.2 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "# En caso de problemas, utilizar las dependencias de librerías de este requierement: https://github.com/googlecolab/backend-info/blob/d6d345cb94fc5fd49951c9af0f6ead5e962bfab2/pip-freeze.txt\n",
        "!pip install numpy==1.23.5\n",
        "!pip install transformers[torch]==4.35.2\n",
        "!pip install accelerate -U\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOub-BB9KWh5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def load_prepare_data(path):\n",
        "  \"\"\"\n",
        "  Función para cargar y procesar datos para el ejercicio.\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(path,sep=\",\")\n",
        "  map_classes = {\n",
        "    \"religion\":1,\n",
        "    \"age\":1,\n",
        "    \"ethnicity\":1,\n",
        "    \"gender\":1,\n",
        "    \"other_cyberbullying\":1,\n",
        "    \"not_cyberbullying\":0,\n",
        "  }\n",
        "  df[\"cyberbullying\"] = df.cyberbullying_type.map(map_classes)\n",
        "  return df[[\"tweet_text\",\"cyberbullying\"]].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeczIz9uKyBV"
      },
      "source": [
        "# Ejercicio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9EFBbmM5w90"
      },
      "source": [
        "En este ejercicio vamos a trabajar con un conjunto de datos procedente de medios sociales online.\n",
        "\n",
        "Uno de los mayores problemas en el internet de hoy en día es la presencia de actitudes negativas hacia algunos colectivos en relación a su etnia, género, religión o ideología política. En este ejercicio trabajaremos con un conjunto de datos reales, etiquetados manualmente, procedentes de la plataforma [Kaggle](https://www.kaggle.com/datasets/andrewmvd/cyberbullying-classification/data). Originalmente, a cada documento del dataset se le asignó una de las siguientes categorías:\n",
        "- *religion*\n",
        "- *age*\n",
        "- *ethnicity*\n",
        "- *gender*\n",
        "- *other_cyberbullying*\n",
        "- *not_cyberbullying*\n",
        "\n",
        "\n",
        "El objetivo inicial del dataset era su uso para entrenar un modelo capaz de detectar el tipo de contenido de odio presente en internet según el colectivo al que se atacaba. En este caso, para simplificar el ejercicio, se ha generado una función `load_prepare_data()` que cambia las categorías del dataset obteníendose al final 2 categorías con valor 1 o 0, indicando si el tweet tiene contenido de odio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c1vV6Aogbxu"
      },
      "source": [
        "**En este ejercicio debeis entrenar un modelo de clasificación utilizando la librería Transformers.** Dado que el análisis exploratorio ha sido realizado en el ejercicio anterior, en este caso podréis centraros en entrenar el modelo utilizando la librería Transformers, seleccionando un modelo pre-entrenado adecuado, entrenando el modelo y llevando a cabo la evaluación.\n",
        "\n",
        "\n",
        "**Nota 1**: Este ejercicio requiere el uso de las GPUs de Google Colab. Este Colab debería estar preconfigurado para ejecutarse en GPU, pero si tuviera problemas en la ejecución que me contacte a través del Moodle para buscar soluciones alternativas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5dR3XnT7Wl1"
      },
      "source": [
        "## 0. Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVOCm6Kw7WCW",
        "outputId": "b789eb3a-650a-416d-fc5c-6332c06bc96d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "from transformers import (\n",
        "   AutoConfig,\n",
        "   AutoTokenizer,\n",
        "   AutoModelForSequenceClassification,\n",
        "   AdamW\n",
        ")\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbiU7iHSKd-9"
      },
      "source": [
        "## 1. Obtención del corpus\n",
        "Para la obtención de los datos teneis disponible la función `load_prepare_data()`. Esta función prepara los datos del ejercicio en formato Pandas dataframe para que podais realizarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kMXGAUdgvKo"
      },
      "outputs": [],
      "source": [
        "path_data = \"https://raw.githubusercontent.com/luisgasco/ntic_master_datos/main/datasets/cyberbullying_tweets.csv\"\n",
        "# Path de datos alternativos en caso de que el anterior no funcione (al estar alojado en github puede haber limitaciones\n",
        "# en la descarga.\n",
        "# path_data = \"https://zenodo.org/records/10938455/files/cyberbullying_tweets.csv?download=1\"\n",
        "dataset = load_prepare_data(path_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "6dXS2-2JgvKo",
        "outputId": "5e820b1b-c157-448d-a01e-09599c150a5d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 47692,\n  \"fields\": [\n    {\n      \"column\": \"tweet_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 46017,\n        \"samples\": [\n          \"@AndyEaston85 Love how we are teaching the Bullshitters a lesson in football. Miss Bully and his message board posts.\",\n          \"GYUK | Anti-feminist YouTuber doubles down on vile Jess Phillips rape joke while leaping to the defence ...: In a video uploaded Thursday (April 23), former UKIP candidate Benjamin jumped to the defence of retired gay porn actor turned men's rights\\u2026 http://dlvr.it/RVRS8h\",\n          \"@Truth_Haqq Islam declared war on all mankind 1400 years ago. Now we return the favor. http://t.co/av4B4yCQzY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cyberbullying\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-18a879ba-c9d7-4a27-b89b-d2c0d0d0cdda\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cyberbullying</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In other words #katandandre, your food was cra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18a879ba-c9d7-4a27-b89b-d2c0d0d0cdda')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18a879ba-c9d7-4a27-b89b-d2c0d0d0cdda button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18a879ba-c9d7-4a27-b89b-d2c0d0d0cdda');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa4fc9ca-47a5-4ec2-ba64-e726890279ce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa4fc9ca-47a5-4ec2-ba64-e726890279ce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa4fc9ca-47a5-4ec2-ba64-e726890279ce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          tweet_text  cyberbullying\n",
              "0  In other words #katandandre, your food was cra...              0\n",
              "1  Why is #aussietv so white? #MKR #theblock #ImA...              0\n",
              "2  @XochitlSuckkks a classy whore? Or more red ve...              0\n",
              "3  @Jason_Gio meh. :P  thanks for the heads up, b...              0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJoVvfp77ZeF"
      },
      "source": [
        "## 2. Análisis exploratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUmXuDMmhtoS"
      },
      "source": [
        "Podéis saltarlo en este ejercicio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wseifFy7b4-"
      },
      "source": [
        "## 3. Preparación de los datos, eleccion del modelo y normalizacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMgDS0Xa_slt"
      },
      "source": [
        "Empezamos por importar el objeto `pipeline` de la libreria `transformers`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aac98seT7cBD",
        "outputId": "9890c948-933b-43f1-c344-3866c25fbf9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsh_NbuN_n81"
      },
      "source": [
        "Ahora creamos las variables separadas del dataset, correspondiendo respectivamente al texto del tweet (`texts`) y el indicador de si es cyberbullying o no (`cyberb`)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-QcfwlHDyMk"
      },
      "outputs": [],
      "source": [
        "texts = dataset.tweet_text.values\n",
        "cyberb = dataset.cyberbullying.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyIWmHkVEoWp"
      },
      "source": [
        "Realizamos la separación de nuestro dataset en muestras para entrenamiento, validación y Test (para la predicción)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RspRlR1En4m"
      },
      "outputs": [],
      "source": [
        "train_texts, test_texts, train_cyberb, test_cyberb = train_test_split(texts, cyberb, test_size=.15, random_state=0,\n",
        "                                                    stratify = cyberb)\n",
        "train_texts, val_texts, train_cyberb, val_cyberb = train_test_split(train_texts, train_cyberb, test_size=.15, random_state=0,stratify = train_cyberb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEu3joE_FThA"
      },
      "source": [
        "Dado que el problema que se presenta a nosotros es un problema de clasificacion, vamos a probar dos modelos proveniente del hub de modelos presentes en la plataforma de HuggingFace : el modelo **bert-base-uncased** porque lo hemos visto en clase, y el modelo **twitter-roberta-base-sentiment-latest** de cardiffnlp. Cada etapa que vamos a realizar a continuacion, lo realizaremos para ambos modelos, agregando \"_twrb\" al segundo para poder identificarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b-d0gG6Et4L"
      },
      "outputs": [],
      "source": [
        "model_name_1 = 'bert-base-uncased'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF93Xv7aFLex"
      },
      "outputs": [],
      "source": [
        "model_name_2 = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6aR1gZ6FgOh"
      },
      "source": [
        "Cargamos los tokenizers de cada uno de los dos modelos gracias a la comanda `AutoTokenizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "892a1d5c8f0b4f559980ce7a1fbc730c",
            "73dac90d567b4c5eb483d66f638cc1d2",
            "237ab350f94d4693b7e59fe29e063146",
            "72240da906594979a5c408cb216dd11b",
            "792f31ef57684755bb14c9f79a84323b",
            "ef5d1b5cb98348379835b631f32862ce",
            "43ebb4080b0f46559642fe438c5b33a3",
            "1e70ded04d7940ae946441628387e053",
            "63fd48de7b924db0a5c917f3131501f2",
            "99996840940444f18321055245bd23e5",
            "0305709f76c84cc698edd26a64ce0fdf",
            "1ce95d527e2047a2a6b876c23f547919",
            "0d1c75f87b5143eeac05550b15ce1093",
            "17f0dcdcf0984a04b5db89c4accbccbd",
            "bbf8e511010549089dc3f6a09ecdb5f0",
            "9d9713f4330446c28ea9c8c13bee7bec",
            "1804d1f358ef48e68be1201f5f20c376",
            "fb718238761a452eb9901597c1e8b2f3",
            "d1e580742d0642679ab9ae3b0122533f",
            "dfdbda19cc7d4cc994d506b1aac0554d",
            "00cf7f757c1946a6b5a309ac78b7a4ef",
            "aa62b20fc8cb4fce9f10c9edd1c76dbc",
            "1e1a37d078c64543b1d0cb3ace89e52f",
            "f514aa9d3cbc4beeb4e5bc34f61f85f7",
            "a23a9bdfb7774f4fbeaa4d051f44d6e3",
            "1d9e8994ffbc4fe5b21cad53002a174f",
            "56e8451cf77f438c8d944257d3add3c1",
            "3f2b94c58218479e908749a1bb384b37",
            "b315e596adc9426ca14022f01544e1cc",
            "670445d0d2c04d4f9d97ee255d91ac09",
            "e124502515db4876b829a960a71749cb",
            "5436c0d1871b491d9a71f09815b8fd58",
            "5e321b2064e54fd88e30576fd37b9dde",
            "ac843c6854d24601a5b5209a9344b4a9",
            "e72db957778f406196904736a596339a",
            "aff020c6794c4ef0a7ec4d2c8596eeaf",
            "10a4637ce14f43788939e70b88b359be",
            "2fe61221c0f2421f894edf175b8083e7",
            "69e505c5c13c4c6e857f10905dd09348",
            "23188eb92dec47c2bb49a9150d0fd64e",
            "e96dc16d8e2a41feb8fc76a8b5bb1f16",
            "8496a2f1af704e28ab9e69d6831a29d8",
            "15700d4703d74f8083f7c0c7d7b6e94d",
            "dd515e6c12e7471cbaab9ee5b43179be"
          ]
        },
        "collapsed": true,
        "id": "0JpnTGqFFiWV",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "6d4df5c3-98fc-47cd-ed9e-b93ecb9428cd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "892a1d5c8f0b4f559980ce7a1fbc730c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ce95d527e2047a2a6b876c23f547919",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e1a37d078c64543b1d0cb3ace89e52f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac843c6854d24601a5b5209a9344b4a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "8c13a7b7bf0440309ea37df608037823",
            "8ef7452bc6cd49ca839d03e75986e126",
            "1d78edb5302d401ea070f63ab71a9a0b",
            "6d96f0774e034aab9b985b0fc4e8e0f7",
            "3e47fb40c10442febf3fdfe9c4ffc781",
            "fec9d676ea654bbba32de382c71005ca",
            "4e43520a270840699d7400f5d82b792e",
            "abc8fb320ec94def8f98b19bfe801dac",
            "b0a9bc9aec6f48d5936316e795ecb771",
            "6a559542b75b47b6ae7388d88227e741",
            "b5eef4563e0d4a65b2603975675707f2",
            "56e9de2559264b21945fc6d88a16b794",
            "9154809af4114f138a99072dd4944114",
            "ccd8dbdc2fde4c20a2db0b16192d7607",
            "ef85ed73d46f4f718d01537ac7775a21",
            "7ae7bb10f0244917a76254e6363ff453",
            "f02fc6a2cfc94db8b5f0f813d31775e1",
            "412d5f016c1140f68f236ff2f6eab203",
            "12ab875da066472997b57865f44d433b",
            "e93cc98713394c8094f8494825d36b73",
            "c200d2d2ef41433f8bf5a9eb6f1b2d5f",
            "e621c8eb8de04e5685d5520cd0babbbb",
            "1a3eb999e4a349f8be471bc23ee192ec",
            "76a34a7d7a95426ab789e62cb3701f89",
            "1cc3204e49414fec86f76474565d307e",
            "5e7278ed5bc7462e8c8bce7b49fdc3d8",
            "18bfbe72360847ca886f625ed1df4e33",
            "53b69f60849f433084285a9afe5e811a",
            "53f8b36ff9ef4d7fb9f34bab1be72641",
            "92bc68309c1d47b29f56352e23d879c9",
            "d86976f5da3c4201bc8d467a9e16ab47",
            "73f333108ea14b8eb5c806c583f3f32f",
            "0bf0577a97b74e7187f6ea402dba22d1",
            "717921eaa44b4e86a55accb807bf29c0",
            "9a5c291adbdd4c30a173ffb982361e37",
            "2e2acae27ff744c5b79204edccf065c1",
            "030755e50f7446c48f8eda1dad2fc668",
            "ad5bf7adf0194d61b6d28026a882af3e",
            "da3e6bb7f1654aec891f79e768429f33",
            "6834662fb33f45a99aff37578e4f9d9c",
            "a8d7a16c9d4340f8b9a0d74befd2b281",
            "d6e7b8add6084c2bb6225d855d2feffd",
            "7054308a22324929a43bf34359a11c4d",
            "c25d54e0bd0d424faba5da48757a4bf1"
          ]
        },
        "collapsed": true,
        "id": "Aq54uxxXFPiE",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "78b1a013-7a7d-4e93-deb6-33555d51719a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c13a7b7bf0440309ea37df608037823",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56e9de2559264b21945fc6d88a16b794",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a3eb999e4a349f8be471bc23ee192ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "717921eaa44b4e86a55accb807bf29c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer_2 = AutoTokenizer.from_pretrained(model_name_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aLJGTQmX67g",
        "outputId": "ec43fccb-590d-4809-c595-343b4e5fc33b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained(model_name_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J19fM47zFjWR"
      },
      "source": [
        "Realizamos un prueba de como funciona el tokenizador con una frase aleatoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hPuZkUkJFi-s",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f691e126-dcbd-4b7c-c37e-f27bdd21ff99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'simple',\n",
              " 'sentence',\n",
              " 'to',\n",
              " 'try',\n",
              " 'the',\n",
              " 'token',\n",
              " '##izer',\n",
              " 'from',\n",
              " 'the',\n",
              " 'model',\n",
              " 'we',\n",
              " 'have',\n",
              " 'chosen',\n",
              " 'on',\n",
              " 'the',\n",
              " 'hugging',\n",
              " '##face',\n",
              " 'platform',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texto = \"This is a simple sentence to try the tokenizer from the model we have chosen on the HuggingFace platform.\"\n",
        "texto_tokens = tokenizer(texto).tokens()\n",
        "texto_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaH8FukOGJfh"
      },
      "source": [
        "Ahora generamos la funcion a continuacion. Esta funcion la usamos en un collab visto en clase y nos permite adaptar nuestros datos de nuestro dataset al formato requerido por el ecosistema de HuggingFace y asi no tener problemas a la hora de utilizar todas las funciones que derivan de los modelos que hemos elegido y extraidos de esta plataforma. La tokenizacion tambien se esta realizando a traves de ella.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQ0xif9TGJzG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        \"\"\"\n",
        "        Constructor de la clase CustomDataset.\n",
        "        Parámetros:\n",
        "        - texts: Lista de textos.\n",
        "        - labels: Lista de etiquetas correspondientes a los textos.\n",
        "        - tokenizer: Objeto del tokenizador a utilizar.\n",
        "        - max_length: Longitud máxima de la secuencia después de la tokenización.\n",
        "        \"\"\"\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Devuelve la longitud del conjunto de datos.\n",
        "        \"\"\"\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Obtiene un elemento del conjunto de datos.\n",
        "\n",
        "        Parámetros:\n",
        "        - idx: Índice del elemento a obtener.\n",
        "\n",
        "        Devuelve:\n",
        "        Un diccionario con 'input_ids', 'attention_mask' y 'labels'.\n",
        "        \"\"\"\n",
        "        # Obtener el texto y la etiqueta del índice proporcionado\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        # Tokenizar el texto\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Devolver el diccionario con los datos\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Jpp7M23Ib3t"
      },
      "source": [
        "La funcion esta cargada, ahora procedemos a transformar nuestros datos al formato Datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqlIHv6ZIZO0"
      },
      "outputs": [],
      "source": [
        "max_length = 280  # Tamano maximo de un tweet\n",
        "\n",
        "train_dataset = CustomDataset(train_texts, train_cyberb, tokenizer, max_length)\n",
        "val_dataset = CustomDataset(val_texts, val_cyberb, tokenizer, max_length)\n",
        "test_dataset = CustomDataset(test_texts, test_cyberb, tokenizer, max_length)\n",
        "\n",
        "train_dataset_2 = CustomDataset(train_texts, train_cyberb, tokenizer_2, max_length)\n",
        "val_dataset_2 = CustomDataset(val_texts, val_cyberb, tokenizer_2, max_length)\n",
        "test_dataset_2 = CustomDataset(test_texts, test_cyberb, tokenizer_2, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPM4ceIJIoGw",
        "outputId": "3b4fd1fe-fb33-4f2f-8e75-04550e062801"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  101, 10166,  1037,  5637,  9040,  8257,  2061,  6616,  2378,  6057,\n",
              "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor(1)}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nLAY-iQR7v9",
        "outputId": "18b13ddd-f284-43b8-a8d4-68fc112347dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    0, 23692,    10,  5100,  5345,  8018,    98, 46922,  6269,     2,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor(1)}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset_2[20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evouAsRCIwEw"
      },
      "source": [
        "Ahora podemos pasar al entrenamiento de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1EtZHFx7ij9"
      },
      "source": [
        "## 4. Entrenamiento y evaluación de modelos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBpJx8Hyk65C"
      },
      "source": [
        "Vamos a hacer uso de la clase `AutoModelForSequenceClassification` de la libreria Transformers para realizar la parte de modelizacion y entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKr2GUiC7iqS",
        "outputId": "6aacc3c7-13f7-4730-e1f8-cb30edfbd589"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "id2label = {0: \"NO_CYBERBULLYING\", 1: \"CYBERBULLYING\"}\n",
        "label2id = {\"NO_CYBERBULLYING\": 0, \"CYBERBULLYING\": 1}\n",
        "model_bbu = AutoModelForSequenceClassification.from_pretrained(model_name_1,  num_labels=2, id2label=id2label, label2id=label2id)\n",
        "model_twrb = AutoModelForSequenceClassification.from_pretrained(model_name_2,  num_labels=2, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E3JoXKlNoUy"
      },
      "outputs": [],
      "source": [
        "import accelerate\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"modelo_test\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EyD5psqNsfX"
      },
      "source": [
        "La siguiente **funcion de metricas** nos permitira realizar una comparativa entre los dos modelos (y tambien con el modelo final elegido del ejercicio 1) y ver cual de los 3 sale mejor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "bdbaf5dfb6df49dcb740bbd25e57a3c3",
            "0431ec5d94ef45af899d26bbe26f2260",
            "20b3b5b9d33442b98253e85d487fb4e9",
            "d88683f99aac41b9856ec3108f17275b",
            "158526d687ce453db0152da60e0e6c57",
            "1d92d47f4d594eeb8e2723ea62a9aa93",
            "10fae8b629b449ca808b55dcfdbd47c5",
            "60bd276924444cdc8c38b2702be30ba6",
            "cfd3a2ecd9864a0380e7bbd0417dc624",
            "53f3a83f1efa411e946652abe7b524df",
            "11bec0ed750b4db79d48115df4ca522d",
            "eb6ecf5f721943398d3fe59298f7671d",
            "382b41bfe8e94fa89a3f59db1d40334c",
            "81f48f43456f493ba7110f27478b675d",
            "80ea21114bff4daa9baa01150c1b5b52",
            "3bff54d02e734b3d94d20949579412fa",
            "2a9353c35141447fa6d829778c9b207a",
            "0ebaff711e9a487d879215c9d87c9ac1",
            "d8d55ad055534eefb32d7ff15e85b0ff",
            "1af02092d50e4378af3e829bc93f6899",
            "d1f028702ca746b98dc2ccf10ece515e",
            "d0af8b1704694554a78990821527c4df"
          ]
        },
        "id": "_8UYOzVINuTM",
        "outputId": "a675a764-4e0f-4665-9546-93cbe573f837"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdbaf5dfb6df49dcb740bbd25e57a3c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb6ecf5f721943398d3fe59298f7671d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1_score = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    accuracy_value = accuracy.compute(predictions=predictions, references=labels)\n",
        "    f1_score_value = f1_score.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_value,\n",
        "        \"f1_score\": f1_score_value,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wav6S5FNyiD"
      },
      "source": [
        "Ajuste del modelo con el objeto `Trainer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqVjucDUN14j",
        "outputId": "545112fd-c564-421a-ca26-226a1bb6d6a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:447: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model_bbu,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "pl9OPka4N4s4",
        "outputId": "ee1f0395-d1e8-4147-c5c4-b6f19dd53c5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4308' max='4308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4308/4308 31:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.261700</td>\n",
              "      <td>0.260864</td>\n",
              "      <td>{'accuracy': 0.8977141917447788}</td>\n",
              "      <td>{'f1': 0.9405126243305278}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"{'accuracy': 0.8977141917447788}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'f1': 0.9405126243305278}\" of type <class 'dict'> for key \"eval/f1_score\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4308, training_loss=0.2747056477581226, metrics={'train_runtime': 1890.7017, 'train_samples_per_second': 18.224, 'train_steps_per_second': 2.279, 'total_flos': 4957978393888800.0, 'train_loss': 0.2747056477581226, 'epoch': 1.0})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtvJ2SQ_TEcw"
      },
      "source": [
        "Ajuste para el segundo modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrJ7kpJqTH4F",
        "outputId": "da6234cf-bb08-4c47-c932-ffa3a3423711"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:447: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainer_twrb = Trainer(\n",
        "    model=model_twrb,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_2,\n",
        "    eval_dataset=val_dataset_2,\n",
        "    tokenizer=tokenizer_2,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "w2DoKGCvTVy8",
        "outputId": "5d519d8b-0e5b-4b70-b009-29e0c321b271"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4308' max='4308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4308/4308 31:40, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.261300</td>\n",
              "      <td>0.275373</td>\n",
              "      <td>{'accuracy': 0.9011675711231706}</td>\n",
              "      <td>{'f1': 0.942493541287915}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"{'accuracy': 0.9011675711231706}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'f1': 0.942493541287915}\" of type <class 'dict'> for key \"eval/f1_score\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4308, training_loss=0.28015478695556867, metrics={'train_runtime': 1902.5196, 'train_samples_per_second': 18.111, 'train_steps_per_second': 2.264, 'total_flos': 4957978393888800.0, 'train_loss': 0.28015478695556867, 'epoch': 1.0})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_twrb.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebLW5MslN9Bi"
      },
      "source": [
        "Ahora que esta entrenado el modelo, pasamos en la parte de evaluacion, usando el metodo 'evaluate' y asi sacaremos las metricas comparativas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "aRkwe1b9OFqd",
        "outputId": "d1fda786-9b8a-4250-b4fe-f2667deb1b1b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='895' max='895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [895/895 02:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"{'accuracy': 0.8922281241263629}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'f1': 0.9374847968864023}\" of type <class 'dict'> for key \"eval/f1_score\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2738875150680542,\n",
              " 'eval_accuracy': {'accuracy': 0.8922281241263629},\n",
              " 'eval_f1_score': {'f1': 0.9374847968864023},\n",
              " 'eval_runtime': 133.567,\n",
              " 'eval_samples_per_second': 53.561,\n",
              " 'eval_steps_per_second': 6.701,\n",
              " 'epoch': 1.0}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "nwZz3qTBU8Bs",
        "outputId": "ac34e10a-1dfc-461e-c835-51586ddf85f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='895' max='895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [895/895 02:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"{'accuracy': 0.8962818003913894}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'f1': 0.9397922752353133}\" of type <class 'dict'> for key \"eval/f1_score\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.285381555557251,\n",
              " 'eval_accuracy': {'accuracy': 0.8962818003913894},\n",
              " 'eval_f1_score': {'f1': 0.9397922752353133},\n",
              " 'eval_runtime': 124.2461,\n",
              " 'eval_samples_per_second': 57.579,\n",
              " 'eval_steps_per_second': 7.203,\n",
              " 'epoch': 1.0}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_twrb.evaluate(test_dataset_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJovajhjl7hn"
      },
      "source": [
        "Antes de visualizar todas las metricas de una manera mas comoda gracias a la matriz de confusion y el classification report, podemos comentar lo visto en la ejecucion anterior. El modelo 1 (Bert Base Uncased) le sale una accuracy de 89,22% y un f1-score del 93,74%. El segundo modelo sale un poquito mejor con una accuracy del 89,62% y un f1-score del 93,97%.\n",
        "\n",
        "Por lo cual en un principio, tendemos a suponer que el modelo 2 es el que mejor sale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kURQWOrqmukZ"
      },
      "source": [
        "Ahora usamos el `predict`del `Trainer` para obtener la prediccion sobre el dataset de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "G08SuuseOLEo",
        "outputId": "7a81ccfa-f6eb-4e3a-d27d-d88a8d8dbe38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predictions = trainer.predict(test_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "M7qTWqFXfg5q",
        "outputId": "be5e5052-cc09-48c6-ccd3-30a213779a09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predictions_twrb = trainer_twrb.predict(test_dataset_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL-rB2LvONxO"
      },
      "outputs": [],
      "source": [
        "y_pred = predictions.predictions.argmax(axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS4M9T_afiPj"
      },
      "outputs": [],
      "source": [
        "y_pred_twrb = predictions_twrb.predictions.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VuhlLIhOPu3"
      },
      "outputs": [],
      "source": [
        "y_true = [x[\"labels\"].item() for x in test_dataset]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF2s0Un5fjUT"
      },
      "outputs": [],
      "source": [
        "y_true_twrb = [x[\"labels\"].item() for x in test_dataset_2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7lQq-gxnCPm"
      },
      "source": [
        "* **Classification Reports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IHHCveoOR3v"
      },
      "source": [
        "Sacamos métricas del modelo *bert base uncased*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_qEiOZWOUMj",
        "outputId": "3236f605-085e-4fff-e3e1-92bff23bd73f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 602  590]\n",
            " [ 181 5781]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.51      0.61      1192\n",
            "           1       0.91      0.97      0.94      5962\n",
            "\n",
            "    accuracy                           0.89      7154\n",
            "   macro avg       0.84      0.74      0.77      7154\n",
            "weighted avg       0.88      0.89      0.88      7154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_true,y_pred))\n",
        "print(classification_report(y_true,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RrpscZkVf6K"
      },
      "source": [
        "Sacamos métricas del modelo *twitter roberta base*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD_v1jFXVkXP",
        "outputId": "83b3fdc9-1f8a-42cc-82a4-42f5db5630d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 621  571]\n",
            " [ 171 5791]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.52      0.63      1192\n",
            "           1       0.91      0.97      0.94      5962\n",
            "\n",
            "    accuracy                           0.90      7154\n",
            "   macro avg       0.85      0.75      0.78      7154\n",
            "weighted avg       0.89      0.90      0.89      7154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_true_twrb,y_pred_twrb))\n",
        "print(classification_report(y_true_twrb,y_pred_twrb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqmnQTwsOY2t"
      },
      "source": [
        "Comparamos con los resultados obtenidos en el ejercicio 1, es decir usando técnicas de ingeniería de características."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGKwCxRSOiUy"
      },
      "source": [
        "* *Resultados del ejercicio 1*\n",
        "\n",
        "                      precision    recall  f1-score   support\n",
        "\n",
        "                0.0       0.49      0.77      0.60      1979\n",
        "                1.0       0.95      0.84      0.89      9903\n",
        "\n",
        "        accuracy                              0.83     11882\n",
        "       macro avg          0.72      0.80      0.75     11882\n",
        "       weighted avg       0.87      0.83      0.84     11882\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWgNB2wogbPJ"
      },
      "source": [
        "* *Resultados del ejercicio 2 - modelo Bert Base Uncased*\n",
        "                    \n",
        "                    precision    recall  f1-score   support\n",
        "\n",
        "                 0       0.77      0.51      0.61      1192\n",
        "                 1       0.91      0.97      0.94      5962\n",
        "\n",
        "      accuracy                               0.89      7154\n",
        "      macro avg          0.84      0.74      0.77      7154\n",
        "      weighted avg       0.88      0.89      0.88      7154"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnAJu-efg2zu"
      },
      "source": [
        "* *Resultados del ejercicio 2 - modelo Twitter Roberta Base Sentiment Latest*\n",
        "                    \n",
        "                      precision    recall  f1-score   support\n",
        "\n",
        "                   0       0.78      0.52      0.63      1192\n",
        "                   1       0.91      0.97      0.94      5962\n",
        "\n",
        "            accuracy                           0.90      7154\n",
        "          macro avg        0.85      0.75      0.78      7154\n",
        "        weighted avg       0.89      0.90      0.89      7154"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i-4bgFgVr2M"
      },
      "source": [
        "La conclusion es que hemos obtenido un mejor resultado usando los metodos de modelos de lenguaje que modelos de ingeniera de caracteristicas. El modelo de cardiffnlp es el que mejor metricas tiene, con una accuracy del 90%. Podemos notar sin embargo que el modelo de regresion logistica del ejercicio 1, a pesar de tener un resultado global mas bajo, tiene un mejor recall para el valor (0.77 vs 0.52).\n",
        "\n",
        "Obviamente, ningun modelo es perfecto y cada uno de los 3 que realizamos requeriria mas tiempo para ajustar sus parametros de manera optima."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}